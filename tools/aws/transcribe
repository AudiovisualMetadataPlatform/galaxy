#!/bin/sh

# Script to run a aws transcribe job using aws-cli.

# Usage:
# transcribe <input_file> <output_file> <audio_format> <s3_bucket> <s3_directory> <job_directory>

# TODO: shall we use ENV var for <S3_bucket> <s3_directory>, <job_directory>? 
# The reason for it is to avoid passing parameter to script each time (although since the script is only called by Galaxy not a human, it probably doesn't matter);
# the reason against it is that it makes the tool less flexible and more dependent.

# record transcirbe command parameters
input_file=$1
output_file=$2
audio_format=$3
s3_bucket=$4
s3_directory=$5
job_directory=$6

# AWS Transcribe service requires a unique job name when submitting a job under the same account. 
# In order to be able to run the same job multilpe times, we can suffix to the job name a seqNo, which increases by 1 each time a new job is submitted.
# In addition, all AWS job related files should go to a designated directory $job_directory, and file names can be prefixed by the job_name. 
# Assume the local job hisotry is preserved as long as the remote AWS history, seqNo can be inferred from the last seqNo used among the job json files.

# find out the next seqNo to use by adding 1 to the largest seqNo used among the existing job json files
job_name_prefix="AwsTranscribe"
last_seqNo=`ls ${job_directory}/${job_name_prefix}-*.* | cut -d "-" -f 2 | cut -d "." -f 1 | sort -rn | head -1`
if [ -z $last_seqNo ]; then
    echo "No previous job files found."
    seqNo=1
else
    echo "Last seqNo used in previous jobs is $last_seqNo"
    seqNo=$((last_seqNo+1))
fi

seqNo=5 #debug
job_name=${job_name_prefix}-${seqNo}
log_file=${job_directory}/${job_name}.log
echo "echo ${input_file} ${output_file} ${audio_format} ${s3_bucket} ${s3_directory} ${job_directory} ${job_name} >> $log_file 2>&1" #debug

#: << '_comment'

# upload media file from local Galaxy source file to S3 directory
#aws s3 cp ${input_file} s3://${s3_bucket}/${s3_directory}/ >> $log_file 2>&1
echo "aws s3 cp ${input_file} s3://${s3_bucket}/${s3_directory}/ >> $log_file 2>&1"

# create json file in the aws directory, i.e. <job_directory>/<job_name>_request.json
request_file=${job_directory}/${job_name}-request.json
input_file_name=$(basename ${input_file})
media_file_url="http://${s3_bucket}.s3.amazonaws.com/${s3_directory}/${input_file_name}"
#media_file_url="http://${s3_bucket}.s3.us-east-2.amazonaws.com/${s3_directory}/${input_file_name}"

# TODO can we use input file extension as the AWS audio format, or does this info need to come from media info which can be done in pre-processing?
# for now we can let user specify it via parameter
### use the last extention as the file format
### input_file_format=${input_file_name##*.}

#jq -n '{ "TranscriptionJobName": "${job_name}", "LanguageCode": "en-US", "MediaFormat": "${audio_format}", "Media": { "MediaFileUri": "${s3_bucket_directory}/${input_file_name}" } }' > ${request_file}
jq -n "{ \"TranscriptionJobName\": \"${job_name}\", \"LanguageCode\": \"en-US\", \"MediaFormat\": \"${audio_format}\", \"Media\": { \"MediaFileUri\": \"${media_file_url}\" } }" > ${request_file}
 
 
# submit transcribe job
echo "aws transcribe start-transcription-job --cli-input-json file://${request_file} >> $log_file 2>&1" #debug
#aws transcribe start-transcription-job --cli-input-json file://${request_file} >> $log_file 2>&1

# wait while job is running
while [ `aws transcribe get-transcription-job --transcription-job-name "${job_name}" --query "TranscriptionJob"."TranscriptionJobStatus" | sed -e 's/"//g'` = "IN_PROGRESS" ] 
do
	echo "Waiting for ${job_name} to finish ..." >> $log_file 2>&1
    sleep 60s
done

# retrieve job response
response_file=${job_directory}/${job_name}-response.json
aws transcribe get-transcription-job --transcription-job-name "${job_name}" > ${response_file}
cat $response_file >> $log_file 2>&1
job_status=`jq '.TranscriptionJob.TranscriptionJobStatus' < $response_file | sed -e 's/"//g'`

echo "Job status: ${job_status}, len: ${#job_status}"

# if job succeeded, retrieve output file URL and download output file from the URL to galaxy output file location
if [ ${job_status} = "COMPLETED" ]; then
    transcript_file_uri=`jq '.TranscriptionJob.Transcript.TranscriptFileUri' < $response_file | sed -e 's/"//g'`
    aws s3 cp $transcript_file_uri $output_file >> $log_file 2>&1
    echo "Job ${job_name} completed in success!" >> $log_file 2>&1
# otherwise print error message to the log and exit with error code
elif [ ${job_status} = "FAILED" ]; then
    echo "Job ${job_name} failed!" >> $log_file 2>&1
    exit 1
else
    echo "Job ${job_name} ended in unexpected status: ${job_status}" >> $log_file 2>&1
    exit 2
fi

#_comment


